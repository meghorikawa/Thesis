\chapter{Methodology}
define  features that I will use for classification how I decided on this and motivation behind these features.


\section{About corpus}
information about the corpus organization, prepossessing

\subsection{J-CAT test}
background and information on the J-CAT test and JLPT

\section{Complexity Measures}
detail the complexity measures I will use, how I developed the scripts to automatically "extract them" and the statistical significance between the proficiency levels
list, Sent Length, Clauses per sentence, Noun phrase length,  Subordination, coordination, noun phrase length, MTLD,Morphological complexity? , ADD measures?

\section{Illustrative descriptors}
Describe the rule based feature matcher I made for extracting certain grammatic patterns to disconcern their use
across proficentcy levels. Mention how many grammar points at each level I was able to include. Use of the lower
levels doesn't disconcern much so focus should be on the intermediate and upper levels.  Forms that are mainly form
based(and therefore easier to pattern match) should be given priority over. Give some examples of rules derrived

In consistency in parsing of 〜切るto show completely finishing an action. 言い切る 売り切る are considered one verb. in the case of 食べ(verb)　切る(非自立可能Verb) and 食べ(Verb) 切れる (AUX 非自立可能)　makes it difficult to when dealing with rule based matching to extract the form..

Also mention that I chose forms which spanned multiple levels. I.e. しか at N4 used with Nouns and しか〜ないat N3 used
with verbs.

Need to mention the feature extractor I am making follows rules for the standardized language which is taught to
learners. Variations due to dialects and causual written variations not included and therefore this would not be
able to extract text with these. Also chose grammar constructs which were largely form based (i.e. easier to extract
vs. use based) and ones that are likely to be used in written language. (leaving out spoken expressions as they
wouldn't likely appear much in writing. )

\section{EBMS}
 Here I will give a breif overview of Explainable boosting machines and why I chose them for my analysis.


% Give up on this part

%\section{Criterial Features}

%\section{Automatic Error Annotation}

%Explain how I will do this so that I will further be able to extract criterial features to examine
% - Automated Error Detection?
%    can I apply an LLM to check each sentence, and then use distance measure to classify errors
%    -what about discourse errors? I have a feeling these will not be caught by an LLM...
%        disregard discourse errors.
%    need some way to measure errors when the corpus is uncorrected.

%    measure correct or incorrect particles?
%    can I train a classifier for automatic error annotation for particles?
%        using SNOW-NLP/snow_simplified_japanese_corpus for training?
%        格助詞 - が, の, を, に, へ, と , で,　から, より
%        係助詞 - は, も, こぞ, でも, しか, さえ, だに
% - Which type of errors will I annotate for?
%        - Automated detection of particle errors - using work?