\chapter{Background/Related Work}
%What do I need to know to understand the approach described in the methodology section?

\section{Linguistic Complexity}
%-What is complexity? How it is defined? in SLA literature?
%-Distiction between complexity, accuracy, and fluency (CAF Framework).
%- Types of Complexity: Syntactic, lexical, morphological, discourse?
%- Why complexity is a useful proxy for proficiency. (motivate what is being measured)
%- Mention Task effect?

% i need to be more explicit in differentiating complexity from criterial features - as to some it may seem like they
% overlap. Frequency measures used
% in
% Complexity look at elaboration whereas the frequency in criterial features focuses on the appearance at different
% levels as a developmental pattern.

In second language acquisition (SLA) research a learner's proficiency is analyzed through the triad of domains known
as \textbf{complexity}, \textbf{accuracy}, and \textbf{fluency} (CAF) \cite{Skehan1989,ellis2003}. Each of these
dimensions are treated as key indicators of language development in a learner, with each dimension capturing different
aspects of learner performance. \textbf{Accuracy} is concerned with the extent a learner's language conforms with
the norms of the target language, usually measured by an error rate. While this seems clear-cut, there is
controversy regarding the criteria for evaluating and identifying errors and how much they should follow
prescriptive norms of the target language \cite{housen2009}. \textbf{Fluency} focuses on the learner's
speed and smoothness of production, measured by counting the rate of production units. Due to the nature of data
needing a time variable, usually oral data is analyzed for these studies. Finally,
\textbf{complexity} is characterized as the ‚Äùthe extent to which the language
produced in performing a task is elaborate
and varied" \cite{ellis2003}. Complexity has attracted considerable attention
in studies analysing written language as a proxy for development.

Despite its widespread use, the concept of complexity has been inconsistently defined across studies. Researchers
have introduced more refined distinctions such as, 'absolute vs relative'
complexity
\citet{Miestamo2008, Butle2012}, and
'linguistic' vs. 'cognitive' complexity \cite{housen2009}. In these models, the first term refers to characteristics
of the linguistic system itself (e.g. structural elaboration), including how complex a sentence is in terms of its
syntax (e.g. number of clauses, subordination, embedding) or its vocabulary (e.g., lexical diversity, word frequency)
. These features can be measured objectively from the surface structure of the texts independent of the learner.
Whereas the second terms (relative and cognitive) focused on the processing demand on the learner or reader.
These distinctions attempt to separate complexity as a
property of the language system from the mental effort required to process it.

Further clarifying this divide, \citet{Pallotti2015} argues for distinguishing between complexity, as the formal
characteristics of linguistic structures, and \textbf{difficulty}, which refers to the cognitive demands those
structures place on learners and readers. According to this view, a sentence may be structurally complext but not
necessarily difficult for a proficient speaker, while a relatively simple structure could still pose challenges for
a learner.

 In line with this perspective, this study adopts a dual approach, considering both formal complexity and
difficulty measures as dimensions of learner language. While structural complexity is quantified through
surface-level linguistc features, difficulty is inferred from how these features are likely to affect processing and
comprehension. For instance, in readability research, studies studies such as \citet{Berendes2018}, used a range of
global and local complexity measures to classify german secondary school texts for readability, while
\citet{shain2016}employed syntactic complexity measures using Dependency Locality Theory (DLT) to predict reading
times as a measure of cognitive load. Similarly, \citet{Feng2009} analyzed discourse level features related to
entity density in texts to assess the readability for adults with intellectual disabilities. % add a note that while

In contrast, most SLA studies on learner writing have focused primarily on linguistic complexity as a developmental
marker, using various measures to model language growth
\cite{Lu2010,Lu2011,Vyatkina2012,weiss2019,Iwashita2006,Wolfe1998, Ortega2003,NorrisOrtega2009}. However,
the majority of studies have focused on the domains of syntax and lexical complexity which has been criticized
as \"reductionist\" and too simplistic of an operationalization of linguistic complexity \cite{Butle2012}. In the
following sections below, I
will analyze the different domains of linguistic complexity used in this thesis.

%- Introduce major complexity metrics:
%    -Syntactic: sentence length, clause density, subordination, coordination, noun phrases, dependency distance
%    - Lexical: type-token ratio (TTR), MTLD, lexical sophistication
%-Theoretical basis and interpretation of each measure and limitations
%- Use of NLP tools in measuring complexity and automated tools in ICALL applications (CTAP)

\subsection{Syntactic Complexity}
%- General overview on types of measures
   % - Elaboration:  \citet{Butle2012}
    %- Variation : Diversity of forms and structures
%- introduce measures, especially ones I plan to use information on the calculations should be given in chapter 3 or
%in appendix?

%- both absolute and relative measures included
    %- mean clause length
    %- mean sent length
    %- clauses to sentences ratio (sentence complexity ratio)
    %- Complex NP per sentence
    %- NP per sentence
    %- coordination
    %- subordination
    %- adjective and adverb verb modifiers per VP?
    %- ADD - average dependency distance?

Syntactic complexity  is concerned with quantifying how elaborate and varied the grammatical structures used in a
    text are. A syntactically complex text often contains more structurally rich constructions, resulting in increased length, depth or diversity. Accordingly, measures of syntactic complexity are often divided into those capturing elaboration- referring to the use of
    longer or more embedded structures, and variation, which refers to the range and diversity of syntactic forms
    used.

\citet{Butle2012} further distinguishes syntactic complexity into two dinmensions of scale: global and local
measures. Global
measures concern the macro-level structural organization of language or what is described as
\textit{"the size, breadth, width, or richness of the
learner's L2 system"} \cite{Butle2012}. These measures are typically operationalized at the sentence or clause level
and include metrics such as mean length of T-unit/sentence, clauses per T-unit/sentence or complex.They reflect
learner's ability to coordinate and embed clauses into hierarchically structured sentences.

In contrast, the local level addresses more fine-grained measures by analyzing
the internal structure at the phrase or clause level. Measures such as length of noun phrases,
modifiers per noun phrase, and Mean hierarchical distance (MHD) are used to analyze the internal strucutre and depth
at a more granular level. These local measures capture how syntactic elements are constructed and nested within
smaller constituents, such as within noun or verb phrases, providing insight into the learner's use of structurally
dense constructions.

For a historical perspective, the majority of syntactic complexity research has focused on absolute measures-those 
based on observable structural features of the langauge that can be quantified independently of the user. These 
measures at the global level are especially based on the T-unit
\footnote{terminable unit, a main clause plus its dependent clasuses
\cite{hunt1965}}, have a long legacy in SLA studies, beginning with oral data \cite{hunt1965} and later applied to
writtern learner data \cite{Ortega2003,Lu2011}. However, other researches implementing automated systems have
preferred to use the sentences \cite{Vyatkina2012,Lu2010}. \citet{Bardovi-Harlig1992} also argued against
artificially segmentind a learner's writing with T-units. As the learner's own knowledge on coordination within
their target language could be unintentionally discounted.

However, more recent approaches to syntactic complexity incorporate relative complexity, or the domain concerned
with processing demand. In this view, the complexity of a structure is not only determined by its length or depth
but by the cognitive effort required to comprehend or produce it. One such class of measures is derived from the 
psycholinguistic models such as Dependency Locality Theory (DLT) \cite{Gibson2000}, which proposes that greater linear distance 
between syntactically dependent elements increases processing load. Measures such as Mean Dependency Distance (MDD)\cite{Liu2008} and Mean Hierarchical Distance (MHD) \cite{Liu2017} have been used in studies to predict reading time and cognitive load \cite{shain2016, Feng2009}, as well as in SLA to model proficiency levels in Japanese learners\cite{Jiang2019,komori2019,Yang2023}. These relative complexity measures allow for a more nuanced view of syntactic complexity that account for both structural elaboration and difficulty in processing. % difficulty really doesn't play a role in my analysis though right? It is at least appealing that I am trying to keep borad measures.


\subsection{Lexical Complexity}
- General overview on what is being measured and motivation behind it
    -difference between lexical words and words
- introduce measures MLTD, CTTR , also mention limitations?
- lexical frequency measures different from syntactic complexity in that they don't quantify elaborateness (relative
complexity measure)?

    - Mean word length in syllables? (via hiragana reading and not kanji)
    - Max word length?
    - MTLD (exclude punctuation)
    - CTTR
    - CTTR for each specific pos (adverbs, adjectives, nouns, verbs, )
    - lexical density of different pos
relative lexical complexity (language use)
    - Average frequency in frequency data-base (JLPT lists)

\subsection{Morphological Complexity}
    - MCI-10 and MCI-5 for nouns verbs and adjectives
    - inflection features, (past tense, passive, causitive)
    - Derivation features (nominalization of type X per token using ÂèØËÉΩ-ÊÄß etc. also Adjectives with ÁöÑÔºü)

%%%%%%%%%%%%%%% Some of the measures below may not be possible to include but I should still movtivate them and
%%%%%%%%%%%%%%%     explain what they measure

\subsection{Discourse Complexity}
Limitations to trying to use measures no available wordbank, etc for Japanese making it difficult to do semantic
complexity measures.
\subsection{Semantic Complexity}
\subsection{Coherence and Cohesion}

\subsection{Linguistic Complexity in SLA}
-Syntactic complexity and lexical measures as indices for proficiency levels of other languages. (Language Developmental Trajectory)
-Use of complexity in SLA studies, readability studies, and ICALL
-role of learner corpora in operationalizing and tracking complexity.
-research on non-English languages
-Existing studies on complexity in L2 Japanese - the limitations

%limitations of independent variables influencing a study such as task conditions, ..... better placed in the SLA
%section?
Studies on Learner Japanese


\citet{komori2019} - Examined MDD and MHD measures in L2 Japanese - found MHD to be a better index between levels,
however only 2 proficiency levels plus small native group was compared
\citet{Iwashita2006} - used syntactic complexity measures on oral corpus.
\citet{Yang2023} - longitudinal study of Chinese native speakers learning Japanese

\section{Criterial Features}
- Define criteria features: What are they and how they relate to CEFR levels.
- Illustrative descriptors vs. criterial features. (EGP)
- Frequency-based indicators of syntactic sophistication? \cite{Ellis2004}
    - comparison to developmental sequences?
- Examples of criterial features in English (and possible other languages) also describe this in relevance to Japanese
- automated extraction - POLKE


\subsection{Proficiency Assessment Frameworks}
- Overview of CEFR levels ( Is it really necessary to include ACFL?)
- The structure and goals of JLPT (grammar/lexicon targets at each level)
- Historical development of JLPT and including of CEFER-style descriptors from 2012.
- limitations of JLPT, or critiques on standardized tests.
Not sure if this warrants it's own section. Describe proficency assesment measures CEFER, etc. also introduce JLPT
Can-do statements- forms teste


maybe also introduce some skepticism of the testing methods of the test?
Talk about previous work with EGP proficiency classification?
Introduce can-do statements at each of the levels and also summarize the equivalent test used in the corpus?


\subsection{Automatic Proficency Assesment}
- motivation - describe why automated is needed
- Overview of existing systems using complexity/criterial features for proficency classification.
- Describe challenges
    - Learner errors impacting feature extraction (decreases robustness)
    -Inconsistent tagging/parsing in morphologically rich or low-resource languages
        -try to find something for Japanese to support some inconsistentices I found when tokenizing sample text
- Describe the aboves' relevance to Japanese, and to this study

\section{Explainable Boosting Machines}
% Overview of what they do and how they work to tie them together with my methodology.Include applications of EBMS in
% SLA and/or compare and contrast other machine learning methods.

