\chapter{Background/Related Work}
%What do I need to know to understand the approach described in the methodology section?

\section{Linguistic Complexity}
%-What is complexity? How it is defined? in SLA literature?
%-Distiction between complexity, accuracy, and fluency (CAF Framework).
%- Types of Complexity: Syntactic, lexical, morphological, discourse?
%- Why complexity is a useful proxy for proficiency. (motivate what is being measured)
%- Mention Task effect?

In second language acquisition (SLA) research a learner's proficency is analyzed through the triad of domains known
as \textbf{complexity}, \textbf{accuracy}, and \textbf{fluency} (CAF) \cite{Skehan1989,ellis2003}. Each of these
dimensions are treated as key indicators of language development in a learner, with each dimension capturing different
aspects of learner performance. \textbf{Accuracy} is concerned with the extent a learner's language conforms with
the norms of the target language, usually measured by an error rate. While this seems clear-cut, there is
controversy regarding the criteria for evaluating and indentifying errors and how much they should follow
prescriptive norms of the target language \cite{housen2009}. \textbf{Fluency} focuses on the learner's
speed and smoothness of production, measured by counting the rate of production units. Due to the nature of data
needing a time variable, usually oral data is analyzed for these studies. Finally,
\textbf{complexity} is characterized as the ‚Äùthe extent to which the language
produced in performing a task is elaborate
and varied" \cite{ellis2003}. Complexity has attracted considerable attention
in studies analysing written language as a proxy for development. However, the concept of complexity itself has
been inconsistently defined, leading to inconsistent findings across studies (this is of course not the only variable).
This underscores the need for more consistent and empirically grounded definition, which may be difficult due to
limitations of independent variables influencing a study such as task conditions, .....

%now I need to provide evidence of inconsistent definitionas of complexity. and then clearly state how I am handling
%this

Definitions of complexity vary across research depending on whether form-based, psycholnguistic, or computational
perspectives are prioritized. To address these differing views reasearchers have proposed further distinctions
to conceptualize complexity more precisely - such as, 'absolute vs relative' complexity
\citet{Miestamo2008, Butle2012}, and
'linguistic' vs. 'cognitive' complexity \cite{housen2009}. In these models, the first term refers to characteristics
of the linguistic system itself (e.g. structural elaboration), including how complex a sentence is in terms of its
syntax (e.g. number of clauses, subordination, embedding) or its vocabulary (e.g., lexical diversity, word frequency)
. These features can be measured objectively from the surface structure of the texts independent of the learner.

In contrast,the second term relates to the cognitive demand placed on the learner or reader - sometimes referred to as \emph{difficulty}- which can vary based on background knowledge, contextual familiarity, and processing ability. This distiction becomes particularly relevant in readability research, where both the linguistic properties of a text and its processing demands are central. For instance, studies such as \citet{Berendes2018}, used a range of global and local complexity measures to classify german secondary school texts for readability, while\citet{shain2016}employed syntactic complexity measures using Dependency Locality Theory (DLT) to predict reading times as an indicator cognitive load. Similarly, \citet{Feng2009} analyzed discourse level features related to entity density in texts to assess the readability for adults with intellectual disabilities. Studies analyzing learner writing development on the other hand, mostly focus on the first characteristic concerned with linguistic features, using many different complexity measures to model learner language and their developmental trajectory\cite{Lu2010,Lu2011,Vyatkina2012,weiss2019,Iwashita2006,Wolfe1998, Ortega2003,NorrisOrtega2009}.

Building on these distinctions, this thesis adopts a hybrid approach to linguistic complexity that draws from both
structural (syntactic, lexical) and processing-baced (cognitive) perspectives. In the following section I outline
the specific features and measures that will be used to quantify complexity in the L2 Japanese learner texts.

% contrast readability studies with writing studies and then introduce how I plan to approach complexity definition
% for a learner corpus....

% This thesis adapts a hybrid approach to complexity to account for theoretical depth and the needs of automated
% assesment. Then talk about syntactic, lexical, etc...

\subsection{Linguistic Complexity in SLA}
-Syntactic complexity and lexical measures as indices for proficiency levels of other languages. (Language Developmental Trajectory)
-Use of complexity in SLA studies, readability studies, and ICALL
-role of learner corpora in operationalizing and tracking complexity.
-research on non-English languages
-Existing studies on complexity in L2 Japanese - the limitations


\subsection{Computational Approaches to Measuring Complexity}
- Introduce major complexity metrics:
    -Syntactic: sentence length, clause density, subordination, coordination, noun phrases, dependency distance
    - Lexical: type-token ratio (TTR), MTLD, lexical sophistication
-Theoretical basis and interpretation of each measure and limitations
- Use of NLP tools in measuring complexity and automated tools in ICALL applications (CTAP)

\section{Criterial Features}
- Define criteria features: What are they and how they relate to CEFR levels.
- Illustrative descriptors vs. criterial features. (EGP)
- Frequency-based indicators of syntactic sophistication? \cite{Ellis2004}
    - comparison to developmental sequences?
- Examples of criterial features in English (and possible other languages) also describe this in relevance to Japanese
- automated extraction - POLKE


\subsection{Proficiency Assessment Frameworks}
- Overview of CEFR levels ( Is it really necessary to include ACFL?)
- The structure and goals of JLPT (grammar/lexicon targets at each level)
- Historical development of JLPT and including of CEFER-style descriptors from 2012.
- limitations of JLPT, or critiques on standardized tests.
Not sure if this warrants it's own section. Describe proficency assesment measures CEFER, etc. also introduce JLPT
Can-do statements- forms teste


maybe also introduce some skepticism of the testing methods of the test?
Talk about previous work with EGP proficiency classification?
Introduce can-do statements at each of the levels and also summarize the equivalent test used in the corpus?


\section{Automatic Proficency Assesment}
- motivation - describe why automatino is needed
- Overview of existing systems using complexity/criterial features for proficency classification.
- Describe challenges
    - Learner errors impacting feature extraction (decreases robustness)
    -Inconsistent tagging/parsing in morphologically rich or low-resource languages
        -try to find something for Japanese to support some inconsistentices I found when tokenizing sample text
- Describe the aboves' relevance to Japanese, and to this study


